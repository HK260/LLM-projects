{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "251f6c0e-4c2e-4bb8-82ef-4282540817c8",
   "metadata": {},
   "source": [
    "# üåê WebPage Summarizer\r\n",
    "\r\n",
    "**Overview**  \r\n",
    "This project is a WebPage Summarizer tool that extracts and condenses key information from any given web page. It utilizes cutting-edge open-source large language models to deliver accurate, concise, and context-aware summaries.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## üîç Models Used\r\n",
    "\r\n",
    "### 1. **LLaMA 3.2**  \r\n",
    "- A powerful and efficient large language model capable of understanding complex web content and producing high-quality natural language summaries.\r\n",
    "\r\n",
    "### 2. **DeepSeek R1:1.5B**  \r\n",
    "- A lightweight yet effective open-source LLM, optimized for faster inference and resource-constrained environments, while still providing meaningful summarization.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## ‚ú® Features\r\n",
    "- Extracts visible text from web pages.\r\n",
    "- Cleans and preprocesses content for LLM input.\r\n",
    "- Generat blogs, or documenta\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c053ab9-4841-44a0-90aa-fcc604034341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install selenium webdriver-manager "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e33be03-2e0b-4167-8392-d42910aa2587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# System & Environment\n",
    "# ===========================\n",
    "import os\n",
    "\n",
    "# ===========================\n",
    "# Web Scraping\n",
    "# ===========================\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ===========================\n",
    "# AI-related\n",
    "# ===========================\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from openai import OpenAI\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406c53f5-0dd4-4d2f-a459-15c2ab707888",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_OLLama=\"llama3.2\"\n",
    "model_deepseek=\"deepseek-r1:1.5b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78937b12-2e49-49b1-a383-630e63dd10d7",
   "metadata": {},
   "source": [
    "# üåê WebScrapping infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e02a00fb-f677-469b-97b8-0b26c4455350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8937c419318242c19913f472681055ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='https://www.nytimes.com/', description='üåê URL:', layout=Layout(width='100%'), placeholder='Enter w‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f811bfeff6942bcb1d1de726784bd5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='ü§ñ Model:', options=(('LLaMA 3.2', 'llama3.2'), ('DeepSeek R1 (1.5B)', 'deepseek-r1:1.5b'‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b45886fb69d4ad39ac0103257791f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='üöÄ Run Scraper & Summarizer', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c647026049ed40999b67c2c032425196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import ollama\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# --------------------------------\n",
    "# Define the DynamicWebScraper class\n",
    "# --------------------------------\n",
    "class DynamicWebScraper:\n",
    "    def __init__(self, url, model_name):\n",
    "        self.url = url\n",
    "        self.model = model_name  # 'llama3.2' or 'deepseek-r1:1.5b'\n",
    "        self.title = \"\"\n",
    "        self.text = \"\"\n",
    "        self.summary = \"\"\n",
    "        self.scrape()\n",
    "        self.generate_summary()\n",
    "        self.shutdown_model()\n",
    "\n",
    "    def scrape(self):\n",
    "        try:\n",
    "            chrome_options = Options()\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "            chrome_options.add_argument(\"--no-sandbox\")\n",
    "            chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "            chrome_options.add_argument(\"--disable-gpu\")\n",
    "            chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "            chrome_options.add_argument(\n",
    "                \"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0\"\n",
    "            )\n",
    "\n",
    "            driver = webdriver.Chrome(\n",
    "                service=Service(ChromeDriverManager().install()), options=chrome_options\n",
    "            )\n",
    "            driver.set_page_load_timeout(30)\n",
    "\n",
    "            print(f\"üîç Loading: {self.url}\")\n",
    "            driver.get(self.url)\n",
    "            time.sleep(5)\n",
    "\n",
    "            self.title = driver.title\n",
    "            html = driver.page_source\n",
    "            driver.quit()\n",
    "            print(f\"‚úÖ Page Loaded: {self.title}\")\n",
    "\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            for tag in soup([\"script\", \"style\", \"img\", \"nav\", \"footer\", \"header\", \"input\", \"button\"]):\n",
    "                tag.decompose()\n",
    "\n",
    "            main = soup.find(\"main\") or soup.find(\"article\") or soup.body\n",
    "            raw_text = main.get_text(separator=\"\\n\", strip=True) if main else soup.get_text()\n",
    "\n",
    "            lines = [line.strip() for line in raw_text.split(\"\\n\") if line.strip()]\n",
    "            self.text = \"\\n\".join(lines[:200])\n",
    "            print(f\"üìÑ Extracted {len(self.text)} characters\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            self.title = \"Error\"\n",
    "            self.text = \"Could not extract content.\"\n",
    "\n",
    "    def generate_summary(self):\n",
    "        try:\n",
    "            if len(self.text) < 100:\n",
    "                self.summary = \"Not enough content to summarize.\"\n",
    "                return\n",
    "\n",
    "            prompt = f\"Summarize the following webpage content:\\n\\n{self.text[:3000]}\"\n",
    "\n",
    "            print(f\"ü§ñ Summarizing using {self.model}...\")\n",
    "            response = ollama.chat(model=self.model, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "            self.summary = response.get(\"message\", {}).get(\"content\", \"Summary not found.\")\n",
    "            print(f\"üìå Summary generated successfully.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to summarize: {e}\")\n",
    "            self.summary = \"Summary generation failed.\"\n",
    "\n",
    "    def shutdown_model(self):\n",
    "        # Ollama handles model lifecycle automatically\n",
    "        # Models are automatically unloaded when not in use\n",
    "        print(f\"‚ÑπÔ∏è Model {self.model} session completed. Ollama will manage cleanup automatically.\")\n",
    "\n",
    "# --------------------------------\n",
    "# UI Widgets\n",
    "# --------------------------------\n",
    "url_input = widgets.Text(\n",
    "    value='https://www.nytimes.com/',\n",
    "    placeholder='Enter website URL',\n",
    "    description='üåê URL:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "model_selector = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('LLaMA 3.2', 'llama3.2'),\n",
    "        ('DeepSeek R1 (1.5B)', 'deepseek-r1:1.5b')\n",
    "    ],\n",
    "    value='llama3.2',\n",
    "    description='ü§ñ Model:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "run_button = widgets.Button(\n",
    "    description='üöÄ Run Scraper & Summarizer',\n",
    "    button_style='success'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# --------------------------------\n",
    "# Callback Function\n",
    "# --------------------------------\n",
    "def run_scraper(button):\n",
    "    with output:\n",
    "        clear_output()\n",
    "\n",
    "        url = url_input.value.strip()\n",
    "        model = model_selector.value.strip()\n",
    "\n",
    "        if not url:\n",
    "            print(\"‚ùå Please enter a valid URL.\")\n",
    "            return\n",
    "\n",
    "        scraper = DynamicWebScraper(url, model)\n",
    "        print(\"\\nüì∞ Title:\", scraper.title)\n",
    "        print(\"üß† Summary:\\n\", scraper.summary)\n",
    "\n",
    "# --------------------------------\n",
    "# Wire the Button\n",
    "# --------------------------------\n",
    "run_button.on_click(run_scraper)\n",
    "\n",
    "# --------------------------------\n",
    "# Display UI\n",
    "# --------------------------------\n",
    "display(url_input, model_selector, run_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d9658e-fc18-4ef5-98b1-83e97cc905af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llms]",
   "language": "python",
   "name": "conda-env-llms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
